{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703ca9de",
   "metadata": {},
   "source": [
    "# Project - Ensemble Techniques - Travel Package Purchase Prediction\n",
    "\n",
    "## Background and Context\n",
    "\n",
    "A tourism company named \"Visit with us\" wants to enable and establish a viable business model to expand the customer base by harnessing the available data of existing and potential customers to make the marketing expenditure more efficient.\n",
    "\n",
    "One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering - Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, it has been observed that 18% of the customers purchased the packages.\n",
    "\n",
    "However, the marketing cost was quite high because customers were contacted at random without looking at the available information.\n",
    "\n",
    "The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being.\n",
    "\n",
    "We are required to analyze the customers' data and information to provide recommendations to the Policy Maker and Marketing Team and also build a model to predict the potential customer who is going to purchase the newly introduced travel package.\n",
    "\n",
    "## Objective\n",
    "\n",
    "To predict which customer is more likely to purchase the newly introduced travel package based on the available data so that customer base can be expanded and the marketing expenditure can be optimized.\n",
    "\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. What are the key factors influencing whether a customer will buy Wellness Tourism Package or not?\n",
    "2. Is there a good predictive model so that we can increase the conversion rate of targetted marketting? \n",
    "3. What does the performance assessment look like for such a model?\n",
    "\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "### Customer details:\n",
    "\n",
    "* CustomerID: Unique customer ID\n",
    "* ProdTaken: Whether the customer has purchased a package or not (0: No, 1: Yes)\n",
    "* Age: Age of customer\n",
    "* TypeofContact: How customer was contacted (Company Invited or Self Inquiry)\n",
    "* CityTier: City tier depends on the development of a city, population, facilities, and living standards. The categories are ordered i.e. Tier 1 > Tier 2 > Tier 3\n",
    "* Occupation: Occupation of customer\n",
    "* Gender: Gender of customer\n",
    "* NumberOfPersonVisiting: Total number of persons planning to take the trip with the customer\n",
    "* PreferredPropertyStar: Preferred hotel property rating by customer\n",
    "* MaritalStatus: Marital status of customer\n",
    "* NumberOfTrips: Average number of trips in a year by customer\n",
    "* Passport: The customer has a passport or not (0: No, 1: Yes)\n",
    "* OwnCar: Whether the customers own a car or not (0: No, 1: Yes)\n",
    "* NumberOfChildrenVisiting: Total number of children with age less than 5 planning to take the trip with the customer\n",
    "* Designation: Designation of the customer in the current organization\n",
    "* MonthlyIncome: Gross monthly income of the customer\n",
    "\n",
    "### Customer interaction data: \n",
    "\n",
    "* PitchSatisfactionScore: Sales pitch satisfaction score\n",
    "* ProductPitched: Product pitched by the salesperson\n",
    "* NumberOfFollowups: Total number of follow-ups has been done by the salesperson after the sales pitch\n",
    "* DurationOfPitch: Duration of the pitch by a salesperson to the customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025505a4",
   "metadata": {},
   "source": [
    "## Import necessary libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36dfb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library to suppress warnings or deprecation notes \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Removes the limit from the number of displayed columns and rows.\n",
    "# This is so that we can see the entire dataframe when we print it\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "# We are setting the random seed via np.random.seed so that\n",
    "# we get the same random results every time\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe311ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Tourism data from sheet Tourism of Tourism.xlsx\n",
    "data = pd.read_excel('Tourism.xlsx', sheet_name='Tourism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6170fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows: {data.shape[0]} and number of columns: {data.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76cc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the last 5 rows of data\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking column names, datatypes and number of non-null values\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d4499",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * CustomerID column can be dropped as it is a unique number and does not contain any useful information.\n",
    "> * There are null or missing values in the data for Age, TypeofContact,  DurationOfPitch, NumberOfFollowups, PreferredPropertyStar, NumberOfTrips, NumberOfChildrenVisiting and MonthlyIncome columns.\n",
    "> * Both numerical and object data type columns are present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a backup of the original dataset\n",
    "data_bkp = data.copy()\n",
    "\n",
    "# Delete the CustomerID column from the working dataset\n",
    "data.drop(['CustomerID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate rows.\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.duplicated()].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5cd48d",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * There are 141 duplicated rows in the current dataset.\n",
    "> * We are going to remove the duplicate rows as they will not help in model building as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11169c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the duplicate rows and reset the index\n",
    "data.drop_duplicates(ignore_index=True, inplace=True)\n",
    "print(f'Number of rows: {data.shape[0]} and number of columns: {data.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Summary of the data\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e064d",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * *ProdTaken*: This is our target variable. Values are 0 or 1. Only 18.8% have 1 values.\n",
    "> * *Age*: Minimum 18 and maximum 61 years with median 36 years. Majority of customers are middle aged.\n",
    "> * *CityTier*: Customers are from three different city tiers. Majority of them are from Tier 3 cities.\n",
    "> * *DurationOfPitch*: Duration of pitch has a mean of 15 (assuming minutes) but there are some outliers. As max and 75 percentile values differ a lot.\n",
    "> * *NumberOfPersonVisiting*: It varies from 1 to 5 person with median of 3. This data looks good.\n",
    "> * *NumberOfFollowups*: Every customer was followed up at least once. Some customers were followed up to 6 times.\n",
    "> * *PreferredPropertyStar*: Varies from 3 to 5 stars ratings with median 3 stars.\n",
    "> * *NumberOfTrips*: Customers atleast had one trip, some customers have more than 20 trips which seems outlier as 75 percentile range is upto 4 trips.\n",
    "> * *Passport*: Around 29% customers have passports.\n",
    "> * *PitchSatisfactionScore*: This feature varies from 1 to 5 with a mean and median as 3.\n",
    "> * *OwnCar*: About 61% customers own a car.\n",
    "> * *NumberOfChildrenVisiting*: Customers took upto maximum of 3 children during their trips. \n",
    "> * *MonthlyIncome*: Monthly income varies from 1K to 98.6K with a median of 25.5K. It seems there are some outliers towards the high end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aada45",
   "metadata": {},
   "source": [
    "Let's check the summary of other categorical variables, including the null values if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = data.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "for col in cat_cols:\n",
    "    print('>> Domain of: ', col)\n",
    "    print('-------------------------------')\n",
    "    cat = data[col].value_counts(dropna=False).sort_values(ascending=False)\n",
    "    print(cat)\n",
    "    print('-------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29dba9",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * *TypeofContact*: There are **25 missing values** otheriwise it has two unique values.\n",
    "> * *Occupation*: Consists of four unique values majority are Salaried and Small Business.\n",
    "> * *Gender*: **143 rows has value \"Fe Male\"** this needs to be treated as **\"Female\"**\n",
    "> * *ProductPitched*: There are 5 different types of products as stated in the problem description.\n",
    "> * *MaritalStatus*: Single and Unmarried will be treated differently based on the advice.\n",
    "> * *Designation*: Looks good with 5 different designations majority are Executive and Manager."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39636e1a",
   "metadata": {},
   "source": [
    "## Fix missing and wrong values\n",
    "We already know that there are null or missing values in many columns and also some wrong values such as \"Fe Male\". Let us fix these issues in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ff2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c146e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the sample data where Age is null to see if there are any patterns\n",
    "data[data.Age.isnull()].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6f453",
   "metadata": {},
   "source": [
    "We see there is no releation between Null values of Age with null values of DurationOfPitch or MonthlyIncome. Null values seems to be random data entry error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58cf6ce",
   "metadata": {},
   "source": [
    "### Fix Gender column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e19fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcting the Gender \n",
    "data['Gender'] = data['Gender'].apply(lambda x: x if x != 'Fe Male' else 'Female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21dbf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c2c67",
   "metadata": {},
   "source": [
    "### Fix TypeofContact column values\n",
    "\n",
    "Null values of TypeofContact will be filled with the mode value since there are only 25 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8fc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Type of contact\n",
    "data['TypeofContact'] = data['TypeofContact'].fillna('Self Enquiry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94978508",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TypeofContact'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e1366",
   "metadata": {},
   "source": [
    "### Fix Age and MonthlyIncome column values\n",
    "\n",
    "Missing values of Age and MonthlyIncome will be replaced with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8395a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Age null values with Median Age\n",
    "for col in ['Age', 'MonthlyIncome']:\n",
    "    data[col] = data[col].fillna(data[col].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c222b23",
   "metadata": {},
   "source": [
    "### Fix Others column values\n",
    "\n",
    "All othere missing values will be filled up with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =['NumberOfFollowups', 'DurationOfPitch', 'PreferredPropertyStar', 'NumberOfTrips', 'NumberOfChildrenVisiting']\n",
    "for col in cols:\n",
    "    data[col] =  data[col].fillna(round(data[col].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1985da3",
   "metadata": {},
   "source": [
    "Finally let's again check if there are any missing values pending to be treated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset has no more missing values, lets take a look at the first 5 rows.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377cad0b",
   "metadata": {},
   "source": [
    "## Univariate Analysis\n",
    "For making the univariate analysis easier, we define below functions that will help us to plot both non-categorical columns such as Age, MonthlyIncome etc. as box and hist plots and categorical columns such as TypeofContact, CityTier, Occupation etc. as count plot with percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot a boxplot and a histogram along the same scale.\n",
    "def box_hist_plot(data, feature, figsize=(12, 7), bins=20):\n",
    "    \"\"\"\n",
    "    This will show a box and hist plot in a column alignment, For hist plot kde is set to True\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    \"\"\"\n",
    "    # creating the 2 subplots\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  \n",
    "    # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.boxplot(data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\")  \n",
    "    # For hist plot\n",
    "    sns.histplot(data=data, x=feature, kde=True, bins=bins, ax=ax_hist2) \n",
    "    # Add mean to the histogram\n",
    "    ax_hist2.axvline(data[feature].mean(), color=\"green\", linestyle=\"--\") \n",
    "    # Add median to the histogram\n",
    "    ax_hist2.axvline(data[feature].median(), color=\"black\", linestyle=\"-\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce83198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create bar plot with percent labels\n",
    "def bar_perc_plot(data, feature):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate the fig width dynamically\n",
    "    total = len(data[feature]) \n",
    "    count = data[feature].nunique()\n",
    "    plt.figure(figsize=(count + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        # Sort the bars from high to low\n",
    "        order=data[feature].value_counts().sort_values(ascending=False).index,\n",
    "    )\n",
    "\n",
    "    for bar in ax.patches:\n",
    "        # percentage of each class of the category\n",
    "        label = \"{:.2f}%\".format(100 * bar.get_height() / total)  \n",
    "        x = bar.get_x() + bar.get_width() / 2  # width of the plot\n",
    "        y = bar.get_height()  # height of the plot\n",
    "\n",
    "        # annotate the percentage\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        ) \n",
    "\n",
    "    plt.show();  # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabafc2f",
   "metadata": {},
   "source": [
    "### Analysis of Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3bd1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age\n",
    "box_hist_plot(data, 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb98e4d",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Majority of customers are between 30 to 40 years.\n",
    "> * Mean and median of the customers are between 35 to 40 years. \n",
    "> * Age is normally distributed and there are no outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec77e28",
   "metadata": {},
   "source": [
    "### Analysis of DurationOfPitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b136a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DurationOfPitch\n",
    "box_hist_plot(data, 'DurationOfPitch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805a356",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Duration of pitch has a right skew because of few outliers.\n",
    "> * Mean and median of pitch is around 15 mins.\n",
    "\n",
    "Pitch durations more than 45 mins seems very odd. We will check the outliers and set it to median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the durations above 45 mins\n",
    "data[data.DurationOfPitch > 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77778511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems there are only two rows with such high values and both of these customers have ot taken the product.\n",
    "# Lets set their value to max 45 mins\n",
    "data['DurationOfPitch'] = data['DurationOfPitch'].apply(lambda x: x if x < 45 else 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14a975",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "box_hist_plot(data, 'DurationOfPitch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3a760",
   "metadata": {},
   "source": [
    "Now the Duration of pitch seems normally distributed although it is right skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a1f4d",
   "metadata": {},
   "source": [
    "### Analysis of MonthlyIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ecf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_hist_plot(data, 'MonthlyIncome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a5792",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Monthly income is also right skewed distribution.\n",
    "> * Median monthly income is around 22K. We are not sure about the currency but outliers which are closed to 100K seems very high.\n",
    "\n",
    "We can guess the monthly income from the median value of income based on designations. But first lets check the outliers which are more than 50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312de78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data.MonthlyIncome > 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f054381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check monthly income median based grouped by designation.\n",
    "data.groupby('Designation')['MonthlyIncome'].apply(lambda x: x.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb373c",
   "metadata": {},
   "source": [
    "Since the outliers are Executive with median income around 20K, it is very unlikely that they will have monthly income around 100K. Lets set these income values to Executive median income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da02d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MonthlyIncome'] = data['MonthlyIncome'].apply(lambda x: x if x < 50000 else 20755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b89ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "box_hist_plot(data, 'MonthlyIncome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f7b6f",
   "metadata": {},
   "source": [
    "Now the Monthly income is centrally distributed although there are outliers but they are acceptable based on the designations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb019cb2",
   "metadata": {},
   "source": [
    "### Analysis of ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f62e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67d749",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Only 18.8% customers have bought travel packages in the given dataset.\n",
    "> * Most of the customers have not bought any travel package, which means we have an unbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1df431",
   "metadata": {},
   "source": [
    "### Analysis of TypeofContact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'TypeofContact')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f85ecab",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Company invited customers are around 29%.\n",
    "> * Self enquiry customers are around 71%. We would have expected that self enquiry customers should by the travel packages but it appears that is not the case, there are factors which are discouraging a self enquired customer to move away and only 18.8% of all customers have bought travel package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76cec81",
   "metadata": {},
   "source": [
    "### Analysis of CityTier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'CityTier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d3d09",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most of the customers are from Tier 1 followed by 2 and 3.\n",
    "> * Tier 3 city customers are very less around 4%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b7361",
   "metadata": {},
   "source": [
    "### Analysis of Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'Occupation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5d96a",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most of the customers are Salaried and Small Business.\n",
    "> * We have around 9% Large Business customers and negligible number of Free Lancers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc570471",
   "metadata": {},
   "source": [
    "### Analysis of Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103bf3d",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Around 60% of our customers are Male.\n",
    "> * A little over 40% customers are Female."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f9e2a",
   "metadata": {},
   "source": [
    "### Analysis of NumberOfPersonVisiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'NumberOfPersonVisiting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64252cf9",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most NumberOfPersonVisiting is 3 followed by 2 and 4 members.\n",
    "> * NumberOfPersonVisiting alone or higher than 4 are very small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f8b3b",
   "metadata": {},
   "source": [
    "### Analysis of NumberOfFollowups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da441865",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'NumberOfFollowups')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d97655",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most of the customers were followed up 4 times followed by 3 and 5 times.\n",
    "> * Number of customers who were followed by for very less time such as 1 or 2 or more than 5 are less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e569f4f",
   "metadata": {},
   "source": [
    "### Analysis of ProductPitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39bd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'ProductPitched')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de258a98",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Basic and Deluxe travel packages were pitched most followed by Standard and Super Deluxe.\n",
    "> * King travel package was offered to only around 7.4% customers.\n",
    "\n",
    "Although the dataset has the above five travel products but for this analysis we are interested in another product namely Wellness Travel Package. During model building we will encode his column as ordered numerical values as we are not interested in these existing products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dca5f",
   "metadata": {},
   "source": [
    "### Analysis of PreferredPropertyStar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'PreferredPropertyStar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f9169",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Around 61% customers preferred 3 star rated properties.\n",
    "> * 5 and 4 star rated properties are prefferred by almost equal number of customers - around 20% each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5d4b8",
   "metadata": {},
   "source": [
    "### Analysis of MaritalStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d661f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'MaritalStatus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d84b7",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most customers around 48% in the dataset are Married.\n",
    "> * Around 20% customers are Divorced followed by Single and Unmarried."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f1d42",
   "metadata": {},
   "source": [
    "### Analysis of NumberOfTrips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a898aa7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'NumberOfTrips')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e659bee",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Around 30% of customers have 2 trips per year followed by 3 and one trip per year.\n",
    "> * There are few customers having 19 or more trips per year which is very unusual.\n",
    "\n",
    "Let's check how many customers have number of trips more than 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba2b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.NumberOfTrips > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cff4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are only 4 customers having Number of trips more than 8. \n",
    "# In order to fix these outliers, for these customers we are going to set the number of trips to 8.\n",
    "data['NumberOfTrips'] = data['NumberOfTrips'].apply(lambda x: x if x < 8 else 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7200240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the distribution of NumberOfTrips after outlier treatment\n",
    "bar_perc_plot(data, 'NumberOfTrips')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4c30d",
   "metadata": {},
   "source": [
    "### Analysis of PitchSatisfactionScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82850f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'PitchSatisfactionScore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0d07c",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Majority of customers (30%) have given satisfaction score as 3.\n",
    "> * However around more than 30% customer has given low satisfaction scores like 1 or 2. Company should investigate this issue.\n",
    "> * Around 40% of customers have given very good satisfaction score either 4 or 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5623e5",
   "metadata": {},
   "source": [
    "### Analysis of OwnCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c46e6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'OwnCar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08f461",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * A little over 60% customers in the dataset own a car.\n",
    "> * However close to 40% customers don't own a car. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3cc69",
   "metadata": {},
   "source": [
    "### Analysis of NumberOfChildrenVisiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e71658",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'NumberOfChildrenVisiting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36533a",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Majority of customers planed to travel had one child followed by 2.\n",
    "> * 22% customers reported no accompanying children.\n",
    "> * 3 or more children accompanied in the trip are very less around 7%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3af42",
   "metadata": {},
   "source": [
    "### Analysis of Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_perc_plot(data, 'Designation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb55e875",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * There are five different designations, majority of the customers are Executive or Manager.\n",
    "> * Higher designation customers such as AVP and VP are less in number. \n",
    "\n",
    "Company designation does not generally decide a person's travel package buying. It is more corelated with Age and monthly income. Hence we are encode this data as ordered numerical feature before running our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b9924",
   "metadata": {},
   "source": [
    "## Multi-Variate Analysis\n",
    "\n",
    "### Distribution of Product Taken with Non-Categorical features\n",
    "\n",
    "Ignoring the outliers let's check the distribution of Product Taken based on the non-categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data[\n",
    "    [\n",
    "        \"Age\",\n",
    "        \"DurationOfPitch\",\n",
    "        \"MonthlyIncome\",\n",
    "        \"NumberOfTrips\"\n",
    "    ]\n",
    "].columns.tolist()\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, variable in enumerate(cols):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    sns.boxplot(data = data, x=\"ProdTaken\", y=variable, showfliers=False)\n",
    "    plt.tight_layout()\n",
    "    plt.title(variable)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed752af",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Mostly younger age people from 25 years to 40 years has taken a travel package.\n",
    "> * Also the customers who have taken a travel package, duration of pitch is higher.\n",
    "> * Relatively lower monthly income group people such as Executives and Managers have taken a travel package.\n",
    "> * Distribution of customers by ProdTaken and NumberOfTrips have no difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90e225",
   "metadata": {},
   "source": [
    "### Distribution of Personal Loan with Categorical features\n",
    "\n",
    "Now let's check the distribution of product taken customers with regards to categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count and a normalized stack bar chart\n",
    "def count_and_normalize_plot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a normalized stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    fig = plt.figure(figsize=(14,5))\n",
    "    \n",
    "    # Add the first plot\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.set_title(predictor + ' by ' + target)\n",
    "    sns.countplot(data = data, x=target, hue=predictor, ax=ax1)\n",
    "\n",
    "    # Add the second plot\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_title('Normalized ' + predictor + ' by ' + target)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, ax=ax2)\n",
    "    plt.legend(\n",
    "        loc=\"lower left\",\n",
    "        frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62d1749",
   "metadata": {},
   "source": [
    "#### TypeofContact Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b92f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'TypeofContact', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e7753",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Self enquiry customers are more in the product taken category which is makes sense.\n",
    "> * However from the normalized chart we see that **higher percentage of company invited customers** have taken a travel package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2045084",
   "metadata": {},
   "source": [
    "#### CityTier Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77af86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'CityTier', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55640c84",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Customers who have taken travel package are mainly from Tier 1 and 3 cities.\n",
    "> * However, normalized chart shows that **higher percentage of Tier 3 city customers** have taken a travel package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca41616",
   "metadata": {},
   "source": [
    "#### Occupation Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'Occupation', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b0e4c",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Salaried and Small business customers are more in the product taken category.\n",
    "> * However **higher percentage of Large Business customers** have taken a travel package.\n",
    "> * Since data points for Free Lancer customers are only 2 we cannot make any conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5b137",
   "metadata": {},
   "source": [
    "#### Gender Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'Gender', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ee8cb",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * More Male customers have taken travel packages.\n",
    "> * Also slightly higher percentage of Male customers have taken a product compared to Female customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5f80e",
   "metadata": {},
   "source": [
    "#### NumberOfPersonVisiting Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e633933",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'NumberOfPersonVisiting', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ccf45f",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Customers who planned to visit with 2 to 4 persons have taken a product.\n",
    "> * Most of the customers who have taken a travel product planned to visit with 3 persons.\n",
    "> * There are no data points for customers who have taken a product and planned to visit wither with 1 or 5 persons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008252e",
   "metadata": {},
   "source": [
    "#### NumberOfFollowups Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d70ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'NumberOfFollowups', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2e621",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most number of customers who took a travel package was followed up 4 times.\n",
    "> * However from the normalized chart we see that **higher percentage of customers taken a product who were followed up more** like 5 or 6 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55900f0",
   "metadata": {},
   "source": [
    "#### ProductPitched Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98985113",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'ProductPitched', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d27d9",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Majority of the customers have taken the basic travel package followed by Standard.\n",
    "> * Basic travel package seems to be popular as higher percentage of customers who were pitched the basic package, have taken it.\n",
    "> * There is not much demand for Super Deluxe and King Travel packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49013e56",
   "metadata": {},
   "source": [
    "#### PreferredPropertyStar Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04397900",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'PreferredPropertyStar', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322cdab5",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most of the customers who took a product preferred 3 start rating properties.\n",
    "> * However **higher percentage of customers who preferred 5 and 4 property ratings** have taken a travel package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b491a57",
   "metadata": {},
   "source": [
    "#### MaritalStatus Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'MaritalStatus', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4ca1b5",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most of the customers who have taken a travel package are single or married followed by unmarried and divorced.\n",
    "> * However from the normalized chart we see that **Single customers stands out** followed by married."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3816827",
   "metadata": {},
   "source": [
    "#### Passport Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'Passport', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90c9da",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Very few about 10% customers who do not have passport, taken a travel package.\n",
    "> * But normalized chart clearly shows that **close to 40% of customers, who have passport, have taken a travel package**. This observation is very encouraging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21404b86",
   "metadata": {},
   "source": [
    "#### PitchSatisfactionScore Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'PitchSatisfactionScore', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59dcc7d",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most of the customers who have taken a travel package gave average 3 pitch satisfaction score.\n",
    "> * Interesting to see that when pitch satisfaction score is 5 higher percentage of customers from this category have taken a travel package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1b097",
   "metadata": {},
   "source": [
    "#### OwnCar Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab43119",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'OwnCar', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c9b47e",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Owning a car did not make much difference with regards to product taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e69ab",
   "metadata": {},
   "source": [
    "#### NumberOfChildrenVisiting Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'NumberOfChildrenVisiting', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73637771",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Self enquiry customers are more in the product taken category which is makes sense.\n",
    "> * However from the normalized chart we see that **higher percentage of company invited customers** have taken a travel package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183be95",
   "metadata": {},
   "source": [
    "#### Designation Vs ProdTaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_and_normalize_plot(data, 'Designation', 'ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b144c6",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Most of the customers who have taken a travel package are Executives, in other words, designation with lowest median monthly salary.\n",
    "> * Higher designation with higher median monthly income have not preferred the travel packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec065f4",
   "metadata": {},
   "source": [
    "Based on the data dictionary and observations we see ProductPitched and Designation values are ordered or ranked in nature. Hence we will encode these features with ordered numerical values. Chances are that Designation and Monthly Income may be highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_bkp2 = data.copy()\n",
    "replaceStruct = {\n",
    "        \"ProductPitched\": {\"Basic\": 1, \"Standard\":2 , \"Deluxe\": 3, \"Super Deluxe\": 4,\"King\": 5},\n",
    "        \"Designation\":     {\"Executive\": 1, \"Manager\": 2 ,\"Senior Manager\": 3 ,\"AVP\": 4, \"VP\": 5}\n",
    "    }\n",
    "data=data.replace(replaceStruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d36fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95957fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between features\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(data.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd35e2",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * As expected Designation and Mothly income are highly correlated (0.85)\n",
    "> * Designation and Product Pitched are also highly correlated (0.82), which again makes sense as company may have pitched higher value products to higer designated customers.\n",
    "> * Similarly we can also see correlation (0.67) between Product Pitched and Monthly income. Although not very strong.\n",
    "> * Number of children visiting and number of persons visiting are also correlated (0.61)\n",
    "> * Age has positive correlation with Monthly Income and Designation which is also self explanatory.\n",
    "> * There is no significant correlation among other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see the pairplot for all numerical variables\n",
    "sns.pairplot(data, hue='ProdTaken');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf05d4",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "We are going to now build several classification models based on Ensemble Techniques. However for each model the evaluation criteria remains same. At the end we'll compare the performance of all the models and provide recommendations for **\"Visit With Us\"** marketing department Wellness Travel Package campaign. We are going to follow below steps:\n",
    "\n",
    "1. Split the data into the train and test set.\n",
    "2. Train models on the training data.\n",
    "3. Try to improve the model performance using hyperparameter tuning.\n",
    "4. Test the performance on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0f5cd",
   "metadata": {},
   "source": [
    "### Model evaluation criterion:\n",
    "\n",
    "### Model can make wrong predictions as:\n",
    "1. Predicting a person who has taken a travel package but in reality he/she did not.\n",
    "2. Predicting a person who did not take a travel package but in reality he/she did.\n",
    "\n",
    "### Which case is more important? \n",
    "\n",
    "* Predicting a person who has taken a travel package but in reality he/she did not then cost related to marketing on travel package to the customer is wasted. While we are looking to optimize the marketting cost but this has less importance than an oppertunity cost. \n",
    "\n",
    "* If we predict a customer who did not take a travel package but in reality he/she did then it will be a loss of oppertunity for the company and this is precisly we want to avoid since we want to increase the customer base of travel package.\n",
    "\n",
    "\n",
    "### How to reduce this loss i.e need to reduce False Negatives?\n",
    "*  `recall` should be maximized, the greater the `recall` higher the chances of identifying customers who would like to buy a the Wellness Tourism Package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17acddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to split data, impute missing values \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Libraries to import decision tree classifier and different ensemble classifiers\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Libtune to tune model, get different metric scores\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8fdde",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the Designation and ProductPitched feature as it is higly correlated with Monthly Income. \n",
    "# Also for ProductPitched, we are not interested in a particular product, since we have new product, \n",
    "# but the end result if the product was taken.\n",
    "X = data.drop(['ProdTaken', 'Designation', 'ProductPitched'], axis=1)\n",
    "y = data['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ea3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)\n",
    "# Splitting data into training and test set:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=1,stratify=y)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab623286",
   "metadata": {},
   "source": [
    "The Stratify arguments maintain the original distribution of classes in the target variable while splitting the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take look at the sample training dataset\n",
    "X.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f00b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85eab9a",
   "metadata": {},
   "source": [
    "In order to calculate different metrics and confusion matrix and promote code reuse we are going to write below utility functions.\n",
    "* The model_performance_classification_sklearn function will be used to check the model performance of models. \n",
    "* The confusion_matrix_sklearn function will be used to plot confusion matrix.\n",
    "* The show_feature_imp function will show the important features for the given model when applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
    "def model_performance_classification_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"Accuracy\": acc,\n",
    "            \"Recall\": recall,\n",
    "            \"Precision\": precision,\n",
    "            \"F1\": f1,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6220b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    To plot the confusion_matrix with percentages\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(predictors)\n",
    "    cm = confusion_matrix(target, y_pred)\n",
    "    labels = np.asarray(\n",
    "        [\n",
    "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
    "            for item in cm.flatten()\n",
    "        ]\n",
    "    ).reshape(2, 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_imp(model):\n",
    "    \"\"\"\n",
    "    Show feature importance from a decision tree type models\n",
    "    \"\"\"\n",
    "    feature_names = X_train.columns\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
    "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661becf",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "d_tree = DecisionTreeClassifier(random_state=1)\n",
    "d_tree.fit(X_train,y_train)\n",
    "\n",
    "#Calculating different metrics\n",
    "d_tree_model_train_perf=model_performance_classification_sklearn(d_tree,X_train,y_train)\n",
    "print(\"Training performance:\\n\",d_tree_model_train_perf)\n",
    "d_tree_model_test_perf=model_performance_classification_sklearn(d_tree,X_test,y_test)\n",
    "print(\"\\nTesting performance:\\n\",d_tree_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "confusion_matrix_sklearn(d_tree,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498bd3b",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * As expected, DecisionTreeClassifier overfits the training dataset with recall score 1.0\n",
    "> * The testing recall is 0.65. Train and test recall scores have big difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff546b",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867cfc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the type of classifier. \n",
    "dtree_estimator = DecisionTreeClassifier(class_weight={0:0.18,1:0.72},random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {'max_depth': [2, 4, 6, 8, None], \n",
    "              'min_samples_leaf': [1, 2, 5, 7, 10],\n",
    "              'max_leaf_nodes' : [2, 3, 5, 10,15],\n",
    "              'min_impurity_decrease': [0.0001,0.001,0.01,0.1]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(dtree_estimator, parameters, scoring=scorer, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "dtree_estimator = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "dtree_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "dtree_estimator_model_train_perf=model_performance_classification_sklearn(d_tree,X_train,y_train)\n",
    "print(\"Training performance:\\n\",dtree_estimator_model_train_perf)\n",
    "dtree_estimator_model_test_perf=model_performance_classification_sklearn(d_tree,X_test,y_test)\n",
    "print(\"Testing performance:\\n\",dtree_estimator_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(dtree_estimator,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c9897",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * After hyperparameter tuning, we do not see much improvement.\n",
    "> * Training and testing recall scores are 1.0 and 0.65 respectively. \n",
    "> * Model is overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_imp(d_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadaab6",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * The model has given high importance to Age, DurationOfPitch, MonthlyIncome, Passport.\n",
    "> * It has also given importance to PitchSatisfactionScore, NumberOfFollowups, Self Enquiry, CityTier. \n",
    "> * It has also given importance to male customers who are single and works in Small and Large businesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d06494",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18082753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "rf_estimator = RandomForestClassifier(random_state=1)\n",
    "rf_estimator.fit(X_train,y_train)\n",
    "\n",
    "#Calculating different metrics\n",
    "rf_estimator_model_train_perf=model_performance_classification_sklearn(rf_estimator,X_train,y_train)\n",
    "print(\"Training performance:\\n\",rf_estimator_model_train_perf)\n",
    "rf_estimator_model_test_perf=model_performance_classification_sklearn(rf_estimator,X_test,y_test)\n",
    "print(\"Testing performance:\\n\",rf_estimator_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(rf_estimator,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a608e0",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Training and testing recall scores are 1.0 and 0.50 respectively.\n",
    "> * The model is highly overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5624b4",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "rf_tuned = RandomForestClassifier(class_weight={0:0.18,1:0.82},random_state=1,oob_score=True,bootstrap=True)\n",
    "\n",
    "parameters = {  \n",
    "                'max_depth': [3, 6, 9, None],\n",
    "                'max_features': ['sqrt','log2',None],\n",
    "                'min_samples_leaf': np.arange(1,15,5),\n",
    "                'min_samples_split': np.arange(2, 20, 5),\n",
    "                'n_estimators': [20,40,80,100]\n",
    "            }\n",
    "\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf_tuned, parameters, scoring=scorer, cv=5, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "rf_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "rf_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99178b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "rf_tuned_model_train_perf=model_performance_classification_sklearn(rf_tuned,X_train,y_train)\n",
    "print(\"Training performance:\\n\",rf_tuned_model_train_perf)\n",
    "rf_tuned_model_test_perf=model_performance_classification_sklearn(rf_tuned,X_test,y_test)\n",
    "print(\"Testing performance:\\n\",rf_tuned_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(rf_tuned,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf36751",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Training and testing recall scores are 0.69 and 0.67 respectively.\n",
    "> * Although the training performance has dropped but the model is not overfitted.\n",
    "> * A good improvement over the last model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ecdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_imp(rf_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb1755",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * The model has given high importance to Passport, Age, Single and Monthly Income.\n",
    "> * It has also given importance to DurationOfPitch, Married, NumberOfFfollowups, Large Business, City Tier\n",
    "> * Very low importance to Self Enquiry or OwnCar features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89412f5e",
   "metadata": {},
   "source": [
    "## Bagging Classifier with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg_bagging_classifier = BaggingClassifier(random_state=1,base_estimator=LogisticRegression(solver='liblinear', random_state=1))\n",
    "lg_bagging_classifier.fit(X_train,y_train)\n",
    "\n",
    "#Calculating different metrics\n",
    "lg_bagging_classifier_model_train_perf=model_performance_classification_sklearn(lg_bagging_classifier,X_train,y_train)\n",
    "print(\"Training performance:\\n\", lg_bagging_classifier_model_train_perf)\n",
    "lg_bagging_classifier_model_test_perf=model_performance_classification_sklearn(lg_bagging_classifier,X_test,y_test)\n",
    "print(\"Testing performance:\\n\", lg_bagging_classifier_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(lg_bagging_classifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f93a0",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Model has given very low recall score both for training and test.\n",
    "> * Although test reacll score is higher than training score but performance is not acceptable.\n",
    "> * For this use case Bagging Classifier with LogisticRegression is not useful.\n",
    "\n",
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "lg_bagging_estimator_tuned = BaggingClassifier(random_state=1, base_estimator=LogisticRegression(solver='liblinear', random_state=1))\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {'max_samples': [0.7,0.8,0.9,1], \n",
    "              'max_features': [0.7,0.8,0.9,1],\n",
    "              'n_estimators' : [10,20,30,40,50],\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(lg_bagging_estimator_tuned, parameters, scoring=scorer, cv=5, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "lg_bagging_estimator_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "lg_bagging_estimator_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "lg_bagging_estimator_tuned_model_train_perf=model_performance_classification_sklearn(lg_bagging_estimator_tuned,X_train,y_train)\n",
    "print(\"Training performance:\\n\", lg_bagging_estimator_tuned_model_train_perf)\n",
    "lg_bagging_estimator_tuned_model_test_perf=model_performance_classification_sklearn(lg_bagging_estimator_tuned,X_test,y_test)\n",
    "print(\"Testing performance:\\n\", lg_bagging_estimator_tuned_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(lg_bagging_estimator_tuned,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9cf76",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * After hyperparameter tuning both training and test recall score is 1.\n",
    "> * Assumption is that it is overfitting both training and test dataset, by reducing the Accuracy and Precision score to very low.\n",
    "> * Since the accuracy and precision score is very low, this model cannot be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da702f9",
   "metadata": {},
   "source": [
    "## Bagging Classifier with DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model, Default base_estimator for BaggingClassifier is DecisionTreeClassifier\n",
    "dt_bagging_classifier = BaggingClassifier(random_state=1)\n",
    "dt_bagging_classifier.fit(X_train,y_train)\n",
    "\n",
    "#Calculating different metrics\n",
    "dt_bagging_classifier_model_train_perf=model_performance_classification_sklearn(dt_bagging_classifier,X_train,y_train)\n",
    "print(\"Training performance:\\n\", dt_bagging_classifier_model_train_perf)\n",
    "dt_bagging_classifier_model_test_perf=model_performance_classification_sklearn(dt_bagging_classifier,X_test,y_test)\n",
    "print(\"Testing performance:\\n\", dt_bagging_classifier_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(dt_bagging_classifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4817b67",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Training and testing recall scores are 0.95 and 0.55 respectively.\n",
    "> * The model is highly overfitted for recall score.\n",
    "> * Although Accuracy and Precision looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808bf6f4",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c08a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "dt_bagging_estimator_tuned = BaggingClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {'max_samples': [0.7,0.8,0.9,1], \n",
    "              'max_features': [0.7,0.8,0.9,1],\n",
    "              'n_estimators' : [20,40,80,100],\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(dt_bagging_estimator_tuned, parameters, scoring=scorer, cv=5, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "dt_bagging_estimator_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "dt_bagging_estimator_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc767106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "dt_bagging_estimator_tuned_model_train_perf=model_performance_classification_sklearn(dt_bagging_estimator_tuned,X_train,y_train)\n",
    "print(\"Training performance:\\n\", dt_bagging_estimator_tuned_model_train_perf)\n",
    "dt_bagging_estimator_tuned_model_test_perf=model_performance_classification_sklearn(dt_bagging_estimator_tuned,X_test,y_test)\n",
    "print(\"Testing performance:\\n\", dt_bagging_estimator_tuned_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(dt_bagging_estimator_tuned,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c6f65",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * After hyperparameter tuning, Training and testing recall scores are 1.0 and 0.60 respectively.\n",
    "> * We don't see much improvement after tuning. The model is highly overfitted for recall score.\n",
    "> * Although Accuracy and Precision have improved.\n",
    "\n",
    "BaggingClassifier does not have feature importance as output param."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2ee84",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "ab_classifier = AdaBoostClassifier(random_state=1)\n",
    "ab_classifier.fit(X_train,y_train)\n",
    "\n",
    "#Calculating different metrics\n",
    "ab_classifier_model_train_perf=model_performance_classification_sklearn(ab_classifier,X_train,y_train)\n",
    "print(\"Training performance:\\n\", ab_classifier_model_train_perf)\n",
    "ab_classifier_model_test_perf=model_performance_classification_sklearn(ab_classifier,X_test,y_test)\n",
    "print(\"Testing performance:\\n\", ab_classifier_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(ab_classifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb777398",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Training and testing recall scores are 0.30 and 0.26 respectively.\n",
    "> * Although the model is not overfitted but recall score is unacceptable.\n",
    "> * Accuracy and Precision looks good for training dataset but not for test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293be76",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "abc_tuned = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {\n",
    "    #Let's try different max_depth for base_estimator\n",
    "    \"base_estimator\":[DecisionTreeClassifier(max_depth=3),DecisionTreeClassifier(max_depth=5),\n",
    "                      DecisionTreeClassifier(max_depth=7)],\n",
    "    \"n_estimators\": [20,40,80,100],\n",
    "    \"learning_rate\":np.arange(0.1,2,0.1)\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter  combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(abc_tuned, parameters, scoring=scorer, cv=5, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "abc_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "abc_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "abc_tuned_model_train_perf=model_performance_classification_sklearn(abc_tuned,X_train,y_train)\n",
    "print(\"Training performance:\\n\", abc_tuned_model_train_perf)\n",
    "abc_tuned_model_test_perf=model_performance_classification_sklearn(abc_tuned,X_test,y_test)\n",
    "print(\"Testing performance:\\n\", abc_tuned_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(abc_tuned,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327db2c9",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * After hyperparameter tuning, Training and testing recall scores are 0.89 and 0.54 respectively.\n",
    "> * There is improvement after tuning the model is highly overfitted for recall score.\n",
    "> * Although Accuracy and Precision have improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_imp(abc_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae087e",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * The model has given high importance to MonthlyIncome, Age and DurationOfPitch.\n",
    "> * It has also given importance to PitchSatisfactionScore, NumberOfTrips, PreferredPropertyStar, Passport\n",
    "> * Very low importance to OwnCar, Salaried and Married customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8baf49",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da44beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "gb_classifier = GradientBoostingClassifier(random_state=1)\n",
    "gb_classifier.fit(X_train,y_train)\n",
    "\n",
    "#Calculating different metrics\n",
    "gb_classifier_model_train_perf=model_performance_classification_sklearn(gb_classifier,X_train,y_train)\n",
    "print(\"Training performance:\\n\",gb_classifier_model_train_perf)\n",
    "gb_classifier_model_test_perf=model_performance_classification_sklearn(gb_classifier,X_test,y_test)\n",
    "print(\"Testing performance:\\n\",gb_classifier_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(gb_classifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca1893",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Training and testing recall scores are 0.43 and 0.34 respectively.\n",
    "> * Although the model is not overfitted but recall score is unacceptable.\n",
    "> * Accuracy and Precision looks good for training dataset but not for test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ff1bb",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebf9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "gbc_tuned = GradientBoostingClassifier(init=AdaBoostClassifier(random_state=1),random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {\n",
    "    \"n_estimators\": [100,150,200,250],\n",
    "    \"subsample\":[0.8,0.9,1],\n",
    "    \"max_features\":[0.7,0.8,0.9,1]\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(gbc_tuned, parameters, scoring=scorer, cv=5, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "gbc_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "gbc_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef00217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "gbc_tuned_model_train_perf=model_performance_classification_sklearn(gbc_tuned,X_train,y_train)\n",
    "print(\"Training performance:\\n\",gbc_tuned_model_train_perf)\n",
    "gbc_tuned_model_test_perf=model_performance_classification_sklearn(gbc_tuned,X_test,y_test)\n",
    "print(\"Testing performance:\\n\",gbc_tuned_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(gbc_tuned,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc234cf",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * After hyperparameter tuning, Training and testing recall scores are 0.60 and 0.42 respectively.\n",
    "> * The scores have slightly improved but recall score is low.\n",
    "> * The model is overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_imp(gbc_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9de627",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * The model has given high importance to Age, MonthlyIncome, Passport and DurationOfPitch.\n",
    "> * It has also given importance to NumberOfFollowups, Single, NumberOfTrips, PreferredPropertyStar, CityTier\n",
    "> * Very low importance to OwnCar, Salaried and Married customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215216d",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "xgb_classifier = XGBClassifier(random_state=1, eval_metric='logloss')\n",
    "xgb_classifier.fit(X_train,y_train)\n",
    "\n",
    "#Calculating different metrics\n",
    "xgb_classifier_model_train_perf=model_performance_classification_sklearn(xgb_classifier,X_train,y_train)\n",
    "print(\"Training performance:\\n\",xgb_classifier_model_train_perf)\n",
    "xgb_classifier_model_test_perf=model_performance_classification_sklearn(xgb_classifier,X_test,y_test)\n",
    "print(\"Testing performance:\\n\",xgb_classifier_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(xgb_classifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b575fb",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Training and testing recall scores are 0.99 and 0.61 respectively.\n",
    "> * This model is giving a better recall score from all previous models on test data.\n",
    "> * Accuracy and Precision looks good for training dataset.\n",
    "> * Model is slightly overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9eaf67",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e46366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "xgb_tuned = XGBClassifier(random_state=1, eval_metric='logloss')\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {\n",
    "    \"n_estimators\": [10,30,50],\n",
    "    \"scale_pos_weight\":[1,2,5],\n",
    "    \"subsample\":[0.7,0.9,1],\n",
    "    \"learning_rate\":[0.05, 0.1,0.2],\n",
    "    \"colsample_bytree\":[0.7,0.9,1],\n",
    "    \"colsample_bylevel\":[0.5,0.7,1]\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(xgb_tuned, parameters,scoring=scorer, cv=5, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "xgb_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "xgb_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "xgb_tuned_model_train_perf=model_performance_classification_sklearn(xgb_tuned,X_train,y_train)\n",
    "print(\"Training performance:\\n\",xgb_tuned_model_train_perf)\n",
    "xgb_tuned_model_test_perf=model_performance_classification_sklearn(xgb_tuned,X_test,y_test)\n",
    "print(\"Testing performance:\\n\",xgb_tuned_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(xgb_tuned,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360143b",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Training and testing recall scores are 0.87 and 0.71 respectively.\n",
    "> * The tuned XGBoost model has given a better recall score then all previous models on test data.\n",
    "> * Accuracy and Precision looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20805085",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_imp(xgb_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ca5a3",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * The model has given high importance to Passport and Single followed by occupation Large Business and PreferredPropertyStar.\n",
    "> * It has also given importance to Unmarried, MonthlyIncome, Age, NumberOfFollowups, DurationOfPitch, CityTier\n",
    "> * Interestingly given low importance to Male, OwnCar, NumberOfPersonVisiting and NumberOfChildrenVisiting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac1b42",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('Ada Boost',AdaBoostClassifier(random_state=1)), ('Gradient Boost',GradientBoostingClassifier(random_state=1))]\n",
    "\n",
    "final_estimator = XGBClassifier(random_state=1, eval_metric='logloss')\n",
    "\n",
    "stacking_classifier= StackingClassifier(estimators=estimators,final_estimator=final_estimator)\n",
    "\n",
    "stacking_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c11cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating different metrics\n",
    "stacking_classifier_model_train_perf=model_performance_classification_sklearn(stacking_classifier,X_train,y_train)\n",
    "print(\"Training performance:\\n\",stacking_classifier_model_train_perf)\n",
    "stacking_classifier_model_test_perf=model_performance_classification_sklearn(stacking_classifier,X_test,y_test)\n",
    "print(\"Testing performance:\\n\",stacking_classifier_model_test_perf)\n",
    "\n",
    "#Creating confusion matrix\n",
    "confusion_matrix_sklearn(stacking_classifier,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8fb3a",
   "metadata": {},
   "source": [
    "> **Observations:**\n",
    "> * Training and testing recall scores are 0.46 and 0.35 respectively.\n",
    "> * Although the model is not overfitted but recall score is not very good.\n",
    "> * Accuracy and Precision looks good for training dataset but not for test dataset.\n",
    "> * More different types of models need to be tried to improve the recall score for StackingClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183c207",
   "metadata": {},
   "source": [
    "## Comparing all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0063570",
   "metadata": {},
   "source": [
    "### Training Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd5682",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training performance comparison\n",
    "models_train_comp_df = pd.concat(\n",
    "    [d_tree_model_train_perf.T,dtree_estimator_model_train_perf.T,rf_estimator_model_train_perf.T,rf_tuned_model_train_perf.T,\n",
    "     dt_bagging_classifier_model_train_perf.T,dt_bagging_estimator_tuned_model_train_perf.T,ab_classifier_model_train_perf.T,\n",
    "     abc_tuned_model_train_perf.T,gb_classifier_model_train_perf.T,gbc_tuned_model_train_perf.T,xgb_classifier_model_train_perf.T,\n",
    "    xgb_tuned_model_train_perf.T,stacking_classifier_model_train_perf.T],\n",
    "    axis=1,\n",
    ")\n",
    "models_train_comp_df.columns = [\n",
    "    \"Decision Tree\",\n",
    "    \"Decision Tree Estimator\",\n",
    "    \"Random Forest Estimator\",\n",
    "    \"Random Forest Tuned\",\n",
    "    \"Bagging Classifier (DT)\",\n",
    "    \"Bagging Estimator Tuned (DT)\",\n",
    "    \"Adaboost Classifier\",\n",
    "    \"Adabosst Classifier Tuned\",\n",
    "    \"Gradient Boost Classifier\",\n",
    "    \"Gradient Boost Classifier Tuned\",\n",
    "    \"XGBoost Classifier\",\n",
    "    \"XGBoost Classifier Tuned\",\n",
    "    \"Stacking Classifier\"]\n",
    "print(\"Training performance comparison:\")\n",
    "models_train_comp_df.T.sort_values(by='Recall', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc571e",
   "metadata": {},
   "source": [
    "### Testing Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ec36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing performance comparison\n",
    "models_test_comp_df = pd.concat(\n",
    "    [d_tree_model_test_perf.T,dtree_estimator_model_test_perf.T,rf_estimator_model_test_perf.T,rf_tuned_model_test_perf.T,\n",
    "     dt_bagging_classifier_model_test_perf.T,dt_bagging_estimator_tuned_model_test_perf.T,ab_classifier_model_test_perf.T,\n",
    "     abc_tuned_model_test_perf.T,gb_classifier_model_test_perf.T,gbc_tuned_model_test_perf.T,xgb_classifier_model_test_perf.T,\n",
    "    xgb_tuned_model_test_perf.T,stacking_classifier_model_test_perf.T],\n",
    "    axis=1,\n",
    ")\n",
    "models_test_comp_df.columns = [\n",
    "    \"Decision Tree\",\n",
    "    \"Decision Tree Estimator\",\n",
    "    \"Random Forest Estimator\",\n",
    "    \"Random Forest Tuned\",\n",
    "    \"Bagging Classifier (DT)\",\n",
    "    \"Bagging Estimator Tuned (DT)\",\n",
    "    \"Adaboost Classifier\",\n",
    "    \"Adabosst Classifier Tuned\",\n",
    "    \"Gradient Boost Classifier\",\n",
    "    \"Gradient Boost Classifier Tuned\",\n",
    "    \"XGBoost Classifier\",\n",
    "    \"XGBoost Classifier Tuned\",\n",
    "    \"Stacking Classifier\"]\n",
    "print(\"Testing performance comparison:\")\n",
    "models_test_comp_df.T.sort_values(by='Recall', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9f436",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c585d74",
   "metadata": {},
   "source": [
    "We analyzed the historical data of \"Visit With Us\" company's previous travel package campaigns and their conversion rate including customer interaction parameters using different EDA techniques. We also explored different Ensemble Techniques, such as Bagging, Boosting and Stacking algorithms to build various predictive models to better understand the features that may have influenced the campaign result.\n",
    "\n",
    "Based on results of EDA and model predictions below conclusions can be draw:\n",
    "\n",
    "* Mostly younger customers between 25 and 40 years of age have taken one of previous the travel packages. And many models such as Random Forest, AdaBoost, GradientBoost have given high importance to Age.\n",
    "* People who have passports seemed to have taken travel packages and models also have given high importance to this feature. Specially XGBoost has given highest importance to Passport.\n",
    "* Customers who are single and unmarried have taken previous travel package more than other statuses and models also predicts the same.\n",
    "* Out of five different occupations (Executive, Manager, Sr. Manager, AVP, VP), relatively lower monthly income occupations such as Executive, Manager and Sr. Manager have preferred to buy a travel package from the company. Since monthly income and designations are correlated. Many models also given high importance to monthly income feature. \n",
    "* Customers location also seems to have an influence in the conversion rate. Customers from Tier 3 cities have taken travel packages more than others.\n",
    "* Occupations in Large Businesses and Salaried seemed to have influence in the deciding if a customer would by a travel package.\n",
    "* Need less to mention that Self Enquired customers definitely have higher chance of taking a travel package.\n",
    "* Many models are also suggesting customers who preferred good hotels/resorts with avobe average property ratings are more likely to buy travel packages.\n",
    "* Other customer features such as Owning a car or number of people or children planning to visit or even gender, number of trips etc. have less importance or significance in decision making for a customer to buy a travel package.\n",
    "\n",
    "On the customer interaction analysis we have some important conclusions as below:\n",
    "\n",
    "* Duration of pitch plays a big role in the conversion rate of potential customer to buy a travel package. Most of the models have given high importance to this feature.\n",
    "* PitchSatisfactionScore is also important factor for many customer in making a decision.\n",
    "* Number of followups in many cases helped deciding a customer to buy previous travel packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad8ef4",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ebf5a",
   "metadata": {},
   "source": [
    "The company \"Visit With Us\" is now planning to launch a new product i.e. Wellness Tourism Package. Based on the previous tavel packages campaign data, analysis and model predictions following recommendations can be provided to policy makers and marketing team to optimize the cost of campaign and increase the customer base.\n",
    "\n",
    "Customers can be profiled to below groups in order of priority as campaigning targets:\n",
    "\n",
    "* Younger aged customers who are single or unmarried and having passports: This group of customers should be the go to customers for the new travel package campaign.\n",
    "* Customers working as Executive, Managers and Sr. Manager in Large Businesses and Salaried occupation are will be the next targets.\n",
    "* Customers residing in Tier 3 and Tier 2 cities and earlier preferred good property ratings, had few number of trips are next.\n",
    "\n",
    "When customer self enquires, sales representatives handling the case should take these customrs seriously with proper product pitch and followups as they have high probability in buying the package.\n",
    "\n",
    "It is recommended that sales representatives are properly trained to give the detailed product pitch on the Wellness Tourism Package, increase their satisfaction score and follow up multiple times as these customer interaction behaviors have high importance towards increasing the customer base. \n",
    "\n",
    "In order to increase the customer base further in future company needs to investigate why earlier travel packages were not popular with aged and wealthy customers with higher designation such as AVP and VP. Also it needs to be investigated how to attract customers from Tier 1 and Tier 2 cities more to increase the customer base in those cities.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
